Te Replit Agent vagy. A feladatod nem “tanácsadás” és nem “kódot írok chatbe”, hanem KONKRÉTAN megépíted a teljes rendszert ebben a Replit projektben: létrehozod/módosítod a fájlokat, lefuttatod a buildet, elindítod a szolgáltatást, és bizonyítod futással, hogy működik.

Nem fogadható el semmilyen kifogás (“nem lehet”, “nem tudom”, “túl nagy”), hanem megcsinálod.

Cél: teljes GLM-4.7-FP8 end-to-end inference engine, 8× NVIDIA B200 (Blackwell) GPU-n Modal.com-on, ≥3000 tokens/s aggregált decode throughputtal, az alábbiakkal KÖTELEZŐEN:
- FA3/TMA-szintű (vagy ahhoz közeli Blackwell-opt) PagedAttention (paged KV cache címzéssel, prefill + decode),
- continuous batching (dinamikus batch, több concurrent request, per-step batch assembly),
- GPU-s sampling (temperature, top-p, repetition penalty, stop token/sequence),
- NCCL alapú multi-GPU tensor parallel + expert parallel (TP/EP) pontosan 8 GPU-n,
- MoE top-k=8, 160 expert (a GLM-4.7 architektúrához igazítva),
- safetensors zero-copy loading (index + header parse + mmap, tényleges pointerek, nincs felesleges másolás),
- compute path-ban TILOS bármilyen standard Python számítás (nincs PyTorch/vLLM/Triton/onnxruntime stb.); Python csak orchestration + tokenizálás + ctypes FFI.

KÖTELEZŐ technológia:
- Futhark: GPU kernel generálás CUDA backenddel (Blackwell optimalizációval).
- Terra: low-level runtime driver, memória-tervezés, CUDA/NCCL integráció, rendszerkomponensek.
- Python 3.11: csak Modal orchestration, tokenizálás, ctypes hívások.

ABSZOLÚT SZABÁLYOK A PROJEKT KÓDJÁRA:
- Komment sehol nem lehet semmilyen fájlban (se # se // se /* */ se --).
- Nincs “TODO”, “FIXME”, “stub”, “placeholder”, “dummy”, “mock”, “simulated”, “example”, “demo”.
- Nincs “…” és nincs “stb.” a kódban (se stringekben, se logokban).
- Minden kód production-ready: teljes logika, teljes error handling, teljes resource cleanup, nincs kihagyott rész.

A te működésed szabályai:
- A chatben NEM paste-elsz kódot. A kódot a Replit fájlokba írod.
- A chatben csak rövid státuszt írsz: “mit módosítottam”, “milyen parancsot futtattam”, “mi lett az eredmény”.
- Ha hibát kapsz, azt a projektben javítod és újrafuttatod, amíg a build és a futás zöld.

Kötelező implementációs pontok:

1) Replit build környezet
- Hozz létre Replit-kompatibilis Nix alapú környezetet, ami friss Replit instance-en kézi lépések nélkül:
  - Futhark nightly CUDA backenddel, CUDA 12.8+ kompatibilitással.
  - Terra LLVM toolchainnel, teljesen működően.
  - CUDA Toolkit + NCCL (Blackwell/B200), nvcc, header, runtime, dev libek.
  - Python 3.11, build toolchain (clang/gcc, cmake, make, pkg-config), zlib, ncurses, gmp, libedit, LLVM dev.
- Beállítod: CUDA_HOME, LD_LIBRARY_PATH, CC/CXX és minden szükséges env var, hogy Futhark+Terra CUDA-t fordítson és linkeljen.

2) Futhark kernerek: GLM-4.7-FP8 teljes forward (92 layer)
- FP8 E4M3 bitpattern i8: helyes dequantize FP16/FP32-be és requantize E4M3-ba rounding+saturation + special case.
- Tensor Core-barát GEMM pipeline és layout (Blackwell optimalizáció).
- Embedding, RMSNorm, MLP (SwiGLU/GEGLU a valós architektúrához), residual/bias fusion.
- RoPE fused: FP8 → deq → RoPE → req egy kernelben, köztes globális tensor nélkül, GLM-4.7 helyes paraméterezéssel.
- Attention: FlashAttention-3 szintű vagy ahhoz közeli Blackwell-opt implementáció:
  - Prefill + decode,
  - numerikusan stabil softmax,
  - paged KV cache indirekció page table-lel,
  - L2-aware tiling, async staging, warp-specialization.
- MoE: 160 expert, top-k=8 routing:
  - router compute, top-k select, token pack/unpack,
  - expert MLP-k FP8 GEMM-ekkel,
  - weighted combine,
  - multi-GPU EP all-to-all NCCL-lel.
- Exportált C kompatibilis entrypointok:
  - prefill (prompt -> KV + logits),
  - decode_step (1 token -> logits + KV update),
  - paraméterek: paged KV, request state, sharding.

3) Terra runtime: engine.so
- Safetensors zero-copy:
  - model.safetensors.index.json parse,
  - shard fájlok mmap,
  - safetensors header parse (data_offsets, dtype, shape),
  - pointerek előállítása másolás nélkül,
  - GLM-4.7 shape/size/alignment validálás.
- Static memory planning:
  - előallokált device bufferek, workspace,
  - nincs per-token alloc,
  - pinned host ahol kell.
- Paged KV cache:
  - page allocator, per-request page table,
  - eviction/compaction.
- Multi-GPU:
  - 8 GPU init, stream/event kezelés,
  - NCCL communicators,
  - TP dense weightsre (heads/hidden sharding) + all-reduce,
  - EP MoE-hoz all-to-all dispatch/gather, overlap compute+comm.
- GPU-s sampling:
  - temperature, top-p, repetition penalty, stop token/sequence GPU-n,
  - minimális host transfer: csak token ID-k vissza.
- Exportált C ABI:
  - init_engine(model_dir, max_batch, max_seq, …) -> handle,
  - prefill(handle, request_id, token_ids_ptr, seq_len, …) -> status,
  - decode_step(handle, request_id, …) -> status + next token buffer,
  - free_engine(handle).

4) Modal orchestration + serving
- Modal image: CUDA 12.8+ devel, telepíted a build dependency-ket, Futhark nightly-t, Terra-t, NCCL-t.
- Pontosan 8× B200: gpu="B200:8".
- Build pipeline run-once:
  - model letöltése volume-ba (zai-org/GLM-4.7-FP8 teljes shardkészlet + tokenizer/config),
  - futhark cuda --library build,
  - Terra build engine.so, linkelve CUDA+NCCL+Futhark libekkel,
  - ctypes betöltés, init_engine egyszer, warm.
- Szerver:
  - concurrent request fogadás,
  - continuous batching scheduler,
  - paged KV cache kezelés,
  - GPU-s sampling,
  - visszaadja a generált szöveget.

Kötelező ellenőrzés:
- A projektben legyen olyan futtatható parancs/entrypoint, amivel:
  - helyben lebuildel a kernel+engine,
  - lefuttat egy rövid prompt->completion inference-et,
  - Modalban deployolható és fut.
- Minden build és futás zöld legyen.

Most AZONNAL kezdd el a projektben a megvalósítást. A chatben a következő üzeneted csak egy rövid státusz legyen arról, hogy mely fájlokat hoztad létre/módosítottad és milyen build parancsot futtattál első lépésként.
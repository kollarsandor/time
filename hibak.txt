A fő hibák / blokkolók (ami miatt most sem korrekt, sem 3k tok/s nem reális)

1) ./run.py jelenleg csak egy toy szimulátor
	•	Nem tölti be a Terra engine.so-t, nem használ CUDA-t, nem futtat transzformert.
	•	tokenize() / detokenize() hamis (ord%1000 + ascii-mókolás) → output értelmetlen.
	•	step() random logitokat gyárt csak 1000 elemig, miközben vocab_size=151552 → mintavételezés hibás modell-univerzum.
	•	stop_sequences paraméter nem működik.

➡️ Következmény: amit “tok/s”-nek mér, az nem a modell, hanem Python-loop + random.

⸻

2) A Terra engine.t jelenleg nem csinál valódi GLM forwardot
	•	run_prefill() csak embedding lookup, nincs attention, nincs KV-cache írás, nincs layer stack, nincs MoE, nincs RMSNorm lánc.
	•	run_decode_step() gyakorlatilag:
	•	lekéri a last token embeddinget
	•	csinál egy lm_head matmult CPU-n
	•	aztán CPU-n sample-ol
	•	Ez nem GLM inference, hanem egy minimál “logitgyártó” helyettesítő.

➡️ Következmény: “production ready” nem lehet, mert a modell outputja nem a modell outputja.

⸻

3) Kritikus teljesítmény-gyilkosok a Terra decode útvonalban
	•	run_decode_step() minden tokenre:
	•	calloc(vocab_size*sizeof(float)) → ~151552 float → oké még, de…
	•	FP8 lm_head teljes dequant f32-re minden stepben:
vocab_size * hidden_dim = 151552*4096 ≈ 620M float ≈ ~2.5 GB tokenenként (!!)
	•	matmul_cpu() O(vocab*hidden) CPU-n, tokenenként

➡️ Ez még 1 tok/s környékén is megdöglik; 3000 tok/s fizikailag kizárt.

⸻

4) API / állapotkezelési bug: RequestState duplikáció + batch leak
	•	Terra prefill():
	•	létrehoz egy belső RequestState* state = create_request_state(...)
	•	add_request_to_batch(handle, state) → batch_state eltárolja a pointert
	•	majd csak mezőket másol a state_out struktúrába (Python ezt kapja)
	•	Python bench.py ezután decode_step(handle, byref(state_copy), ...)-t hív.
	•	Ez a másolat állapotát módosítja, nem a batch-ben tárolt eredetit.
	•	free_request_state() nem hívja a free_request_state_internal()-t →
nem adja vissza a KV page-eket, és a batch-ben lévő request sem kerül kiszedésre.

➡️ Következmény: memória/KV-page leak, batch_state szemét, inkonzisztens állapot, hosszabb futásnál szétesik.

⸻

5) Safetensors parser: nem biztonságos, nem korrekt
	•	parse_safetensors_header() a header JSON-t null-terminátor nélkül kezeli strstr-rel → túlolvasás / random match / crash.
	•	parse_safetensors_index() az entry-számlálás heurisztikus → könnyen rossz.
	•	Dtype mapping részben oké, de a feldolgozás nem robust.

➡️ Következmény: weights betöltés megbízhatatlan.

⸻

6) KV-cache méretezés hibás / duplázások
	•	bytes_per_page képlete keveri a “K+V” szorzót és a tényleges elem-bytes-t.
	•	total_kv_size számítás így könnyen félreallokál (túl kevés / túl sok), ami GPU-n memóriakorrupt, CPU-n pazarlás.

⸻

7) Multi-GPU csak “dísz”
	•	NCCL init csak struktúrákat tölt, nincs ncclCommInitRank, nincs all-reduce/all-gather a compute útvonalban.
	•	Nincs tensor parallel / expert parallel valós implementáció.

⸻

8) build.sh / CUDA build “oké”-nak tűnik, de productionhoz hiányos
	•	Nincs arch flag Blackwellre (B200). Modalon ez kritikus lehet.
	•	A .so-k elkészülnek, de az engine nem biztos, hogy ezeket ténylegesen használja (jelenleg sok kernel csak stub-szinten “deklarált”).

⸻

Következő prompt az agentnek (copy-paste, kompromisszum nélkül, production-ready célra)

FELADAT: A repo-t production-ready GLM-4.7-FP8 inference engine-gé kell tenni úgy, hogy a modell és a minőség NEM változhat, a cél pedig 8x B200-on >= 3000 tok/s (aggregate) folyamatos batchinggel. Nincs kompromisszum: a toy/random logit útvonalakat teljesen ki kell dobni. A deliverable elsőre működjön: ./run.py legyen a fő belépési pont.

0) KÖTELEZŐ ELFOGADÁSI KRITÉRIUMOK
- ./run.py --smoke: valódi tokenizálás + valódi modell forward (nem random), helyes szöveg dekódolás.
- ./run.py --bench: mérés és report (tok/s, p50/p99 ms/token, batch size). Modal 8x B200-on el kell érnie a >= 3000 tok/s-t.
- Nincs per-token óriás-allokáció, nincs per-token full lm_head dequant CPU-ra.
- Nincs leak (KV page visszaadás, request state életciklus korrekt).
- Multi-GPU ténylegesen használva (tensor parallel és/vagy expert parallel + NCCL collectives), nem csak “num_gpus” változó.

1) RUN.PY REWRITE (toy kód kidobása)
- run.py NE tartalmazzon random logits/szimulátor engine-t.
- run.py töltse be a buildelt engine.so-t ctypes-szel (mint bench.py, de kijavítva).
- Kötelező módok:
  - ./run.py --smoke --model ./model --engine ./build/engine.so
  - ./run.py --bench --duration 60 --concurrency 64 --prompt-len 256 --gen-len 256
  - ./run.py --serve (egyszerű HTTP JSON API elég: /generate streaming opcionális, de a perf cél miatt ajánlott)
- Tokenizer: transformers AutoTokenizer kötelező; fallback tilos (nincs ord%1000).

2) TERRA ENGINE API FIX (kritikus)
- A RequestState NEM lehet “kimásolt struct” a Python oldalon.
- Vezess be OPAQUE pointer API-t:
  - prefill(...) -> RequestState* (visszaadott pointer)
  - decode_step(handle, RequestState*, ...) (ugyanazt a pointert használja)
  - free_request_state(handle, RequestState*) -> a belső free_request_state_internal-t hívja (KV page free + batch remove)
- Alternatíva: teljes batch decode C/Terra oldalon:
  - add_request(handle, ...) -> RequestState*
  - run_batch_decode(handle, RequestState** states, int n, int64* out_tokens, uint8* out_done)
  - Python csak schedulerez és egyetlen batch hívást csinál stepenként.
- BÁRMELYIKET választod: szüntesd meg a jelenlegi “add_request_to_batch + state_out másolat” inkonzisztenciát.

3) SAFETENSORS LOADER ROBUSZTUSSÁ TÉTELE
- parse_safetensors_header: a header_json-t másold ki egy új bufferbe és null-termináld, mielőtt strstr/parse fut.
- index parser: ne heurisztikával számolj entry-t; parse-old a JSON-t rendesen (legalább egy minimal JSON parser vagy a safetensors header formátum korrekt feldolgozása).
- Biztosítsd: tensor offset, dtype, shape 100% helyes.

4) VALÓDI GLM FORWARD IMPLEMENTÁCIÓ (decode + prefill)
- Implementáld a teljes forward pass-t:
  - embedding -> (rétegenként) RMSNorm -> QKV proj (FP8 GEMM cublasLt) -> RoPE -> paged attention (KV-cache írás/olvasás) -> o_proj -> residual
  - MLP/MoE: router + top-k expert, expert GEMM-ek, combine, residual
  - final norm + lm_head
- Minden súly GPU memóriában (FP8), per-tensor scale kezelés kötelező.
- KV-cache GPU-n, page table GPU/CPU szinkron minimális, decode-ben csak szükséges.

5) SAMPLING GPU-N, BATCH-BEN
- Használd a meglévő kernel interface-eket:
  - launch_apply_rep_penalty
  - launch_top_p_sampling
  - launch_argmax (debug)
- A sampling batch-ben fusson, és csak a kiválasztott tokenek jöjjenek vissza hostra.
- Stop tokenek támogatása token-id alapon.

6) MULTI-GPU: TENSOR PARALLEL + NCCL
- Implementáld legalább a standard TP-t:
  - lineár rétegek shardolása (column/row parallel), szükséges all-reduce / all-gather NCCL-lel.
- MoE expert shardolás: experts per GPU, all-to-all/dispatch + combine (ha a modell ezt igényli).
- NCCL-t ténylegesen initeld (ncwCommInitRank) és használd a wrapper függvényeket.

7) BUILD.SH + MODAL APP PRODUKCIÓSÍTÁS
- build.sh:
  - add arch flags B200-hoz (Blackwell), és Release build.
  - engine.so kerüljön a ./build-be, és LD_LIBRARY_PATH helyesen legyen beállítva.
- modal_app.py:
  - build lépések automatikusan fussanak (futhark/terra/cuda wrappers).
  - benchmark entrypoint: modal run ... -> ugyanazt a --bench reportot adja.

8) TESZTEK / VALIDÁCIÓ (kötelező, “elsőre production-ready” miatt)
- Smoke teszt: 5 prompt, determinisztikus seed, összehasonlítás Transformers referencia outputtal (legalább a token-id prefix egyezzen N tokenig).
- Leak teszt: 10k decode step sok requesttel, KV pages visszaáll, RAM/GPU memória nem nő.
- Perf teszt: reportolja a tok/s-t és a batch statokat.

9) TILALMAK
- Tilos random logits, toy tokenizer, CPU lm_head dequant per token, per token óriás malloc/calloc.
- A modell paraméterek/arch NEM változhatnak.

DELIVERABLE: egy PR-szerű változtatáscsomag, amiben:
- ./run.py a fő belépési pont
- a Terra engine API kijavítva (opaque state)
- valós forward + batch decode + GPU sampling
- Modal deploy + bench működik
- a bench outputban megvan a >=3000 tok/s cél 8x B200-on.

Ha ezt az agent pontosan végigcsinálja, akkor onnantól tényleg van esélyed a 3k tok/s-re – de jelen állapotban a rendszer még nem “lassú”, hanem nem is ugyanazt a problémát oldja meg (nem futtat GLM-et).